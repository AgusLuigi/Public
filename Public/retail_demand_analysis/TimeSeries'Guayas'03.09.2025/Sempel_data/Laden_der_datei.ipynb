{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c27fc9eb",
   "metadata": {},
   "source": [
    "# Laden Local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed3542e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import io\n",
    "import os\n",
    "import time\n",
    "import gdown\n",
    "\n",
    "file_ids = {\n",
    "    \"holiday_events\": \"1RMjSuqHXHTwAw_PGD5XVjhA3agaAGHDH\",\n",
    "    \"items\": \"1ogMRixVhNY6XOJtIRtkRllyOyzw1nqya\",\n",
    "    \"oil\": \"1Q59vk2v4WQ-Rpc9t2nqHcsZM3QWGFje_\",\n",
    "    \"stores\": \"1Ei0MUXmNhmOcmrlPad8oklnFEDM95cDi\",\n",
    "    \"transactions\": \"1PW5LnAEAiL43fI5CRDn_h6pgDG5rtBW_\", \n",
    "    \"train\": \"1oEX8NEJPY7wPmSJ0n7lO1JUFYyZjFBRv\" \n",
    "}\n",
    "\n",
    "# Pfad zur lokal gespeicherten, großen Datei\n",
    "LOCAL_TRAIN_FILE_PATH = \"Sempel_data/train.csv\"\n",
    "N_ROWS_TO_LOAD = 2_000_000\n",
    "DOWNLOAD_DIR = \"Sempel_data\"\n",
    "\n",
    "# Build das direct download URL from a file ID\n",
    "def make_drive_url(file_id):\n",
    "    \"\"\"Erstellt die direkte Download-URL aus der Datei-ID.\"\"\"\n",
    "    return f\"https://drive.google.com/uc?id={file_id}\"\n",
    "def download_file_if_missing(file_name, file_id):\n",
    "    \"\"\"Prüft, ob eine Datei lokal existiert und lädt sie ansonsten mit gdown herunter.\"\"\"\n",
    "    local_path = os.path.join(DOWNLOAD_DIR, file_name)\n",
    "    \n",
    "    if os.path.exists(local_path):\n",
    "        print(f\"Datei '{file_name}' existiert bereits lokal. Überspringe Download.\")\n",
    "        return local_path\n",
    "    print(f\"Lade '{file_name}' von Google Drive (ID: {file_id})...\")\n",
    "    url = make_drive_url(file_id)\n",
    "    \n",
    "    try:\n",
    "        if not os.path.exists(DOWNLOAD_DIR):\n",
    "            os.makedirs(DOWNLOAD_DIR)\n",
    "            \n",
    "        gdown.download(url, local_path, quiet=False)\n",
    "        print(f\"Download von '{file_name}' abgeschlossen.\")\n",
    "        return local_path\n",
    "    except Exception as e:\n",
    "        print(f\"SCHWERER FEHLER beim Download von '{file_name}' mit gdown: {e}\")\n",
    "        return None\n",
    "\n",
    "# Helper function to load a CSV from a local path\n",
    "def load_csv_from_local(local_path, name, nrows=None):\n",
    "    \"\"\"Lädt eine CSV-Datei von einem lokalen Pfad in einen DataFrame.\"\"\"\n",
    "    print(f\"Lade '{name}' (lokal)...\")\n",
    "    start_time = time.time()\n",
    "    try:\n",
    "        df = pd.read_csv(\n",
    "            local_path, \n",
    "            nrows=nrows, \n",
    "            low_memory=False\n",
    "        )\n",
    "        load_time = int(time.time() - start_time)\n",
    "        print(f\"'{name}' erfolgreich geladen. Zeilen: {len(df):,}. Zeit: {load_time}s.\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"FEHLER beim Laden der lokalen CSV-Datei '{name}': {e}\")\n",
    "        return None\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    # Stellen Sie sicher, dass gdown installiert ist\n",
    "    try:\n",
    "        import gdown\n",
    "    except ImportError:\n",
    "        print(\"FEHLER: Das 'gdown'-Paket ist nicht installiert.\")\n",
    "        print(\"Bitte führen Sie im Terminal aus: pip install gdown requests\")\n",
    "        exit()\n",
    "    dataframes = {}\n",
    "    \n",
    "    # 1. Lade alle kleineren DataFrames und die große Datei train.csv\n",
    "    print(\"--- 1. Download fehlender und Laden aller DataFrames ---\")\n",
    "    \n",
    "    for name, file_id in file_ids.items():\n",
    "        file_name = f\"{name}.csv\"\n",
    "        local_path = download_file_if_missing(file_name, file_id)\n",
    "        if local_path is None:\n",
    "            continue \n",
    "        if name == \"train\":\n",
    "            df = load_csv_from_local(local_path, name, nrows=N_ROWS_TO_LOAD)\n",
    "        else:\n",
    "            df = load_csv_from_local(local_path, name)\n",
    "            \n",
    "        if df is not None:\n",
    "            dataframes[f\"df_{name}\"] = df\n",
    "    \n",
    "    # 2. Zusammenfassung und Zuweisung zu einzelnen Variablen\n",
    "    \n",
    "    if dataframes:\n",
    "        print(\"Alle DataFrames erfolgreich geladen:\")\n",
    "        globals().update(dataframes)\n",
    "        for name, df in dataframes.items():\n",
    "            print(f\"- {name}: {df.shape[0]:,} Zeilen, {df.shape[1]} Spalten.\")\n",
    "            \n",
    "    else:\n",
    "        print(\"Keine DataFrames konnten geladen werden. Bitte prüfen Sie die Fehlermeldungen oben.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9951731c",
   "metadata": {},
   "source": [
    "# Laden auf googleDrive um mit Coolab zu arbeiten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d059ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import io\n",
    "\n",
    "# Build the direct download URL from a file ID\n",
    "def make_drive_url(file_id):\n",
    "    return f\"https://drive.google.com/uc?id={file_id}\"\n",
    "\n",
    "# Helper function to load a CSV from a direct URL\n",
    "def load_csv_from_url(url):\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()  # Raises an error if the request fails\n",
    "    return pd.read_csv(io.StringIO(response.text))\n",
    "\n",
    "# Dictionary of file IDs for clarity\n",
    "file_ids = {\n",
    "    \"holiday_events\": \"1RMjSuqHXHTwAw_PGD5XVjhA3agaAGHDH\",\n",
    "    \"items\": \"1ogMRixVhNY6XOJtIRtkRllyOyzw1nqya\",\n",
    "    \"oil\": \"1Q59vk2v4WQ-Rpc9t2nqHcsZM3QWGFje_\",\n",
    "    \"stores\": \"1Ei0MUXmNhmOcmrlPad8oklnFEDM95cDi\",\n",
    "    \"train\": \"1oEX8NEJPY7wPmSJ0n7lO1JUFYyZjFBRv\",\n",
    "    \"transactions\": \"1PW5LnAEAiL43fI5CRDn_h6pgDG5rtBW_\"\n",
    "}\n",
    "\n",
    "# Load each CSV using the helper functions\n",
    "df_holiday_events = load_csv_from_url(make_drive_url(file_ids[\"holiday_events\"]))\n",
    "df_items          = load_csv_from_url(make_drive_url(file_ids[\"items\"]))\n",
    "df_oil            = load_csv_from_url(make_drive_url(file_ids[\"oil\"]))\n",
    "df_stores         = load_csv_from_url(make_drive_url(file_ids[\"stores\"]))\n",
    "# df_train          = load_csv_from_url(make_drive_url(file_ids[\"train\"])) we dont read it as the file is too big and wont work this way\n",
    "df_transactions   = load_csv_from_url(make_drive_url(file_ids[\"transactions\"]))\n",
    "\n",
    "# ---------------------\n",
    "\n",
    "# Download the file using gdown\n",
    "gdown.download(make_drive_url(file_ids[\"train\"]), \"train.csv\", quiet=False)\n",
    "!pip install -q \"dask[dataframe]\"\n",
    "\n",
    "import gdown\n",
    "\n",
    "# Use our existing function to build the download URL\n",
    "train_url = make_drive_url(file_ids[\"train\"])\n",
    "\n",
    "# Download the file using gdown\n",
    "gdown.download(train_url, \"train.csv\", quiet=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
